---
title: Langfuse Service
description: Monitor and trace AI agent interactions with Langfuse integration
---

# Langfuse Service

Langfuse provides comprehensive observability for AI applications, offering detailed tracing, monitoring, and analytics for your ARK agents and teams. This guide covers setting up and using Langfuse with ARK.

## Overview

Langfuse integration with ARK provides:
- **LLM Call Tracing** - Track all model interactions and API calls
- **Cost Monitoring** - Monitor API usage and associated costs
- **Performance Analytics** - Response times, throughput, and latency metrics
- **Session Management** - Group related interactions and conversations
- **Error Tracking** - Identify and debug issues in agent workflows

## Installation

### Quick Start

Deploy Langfuse as part of your ARK installation:

```bash
# From repository root - install Langfuse with headless initialization
make langfuse-install

# Show credentials and access instructions
make langfuse-credentials
```

### Headless Initialization

Langfuse is automatically configured with:
- **Organization**: `ark`
- **Project**: `ark`
- **User**: `ark@ark.com` / `password123`
- **API Keys**: Pre-configured for OpenTelemetry integration

The installation automatically:
1. Deploys Langfuse to the `telemetry` namespace
2. Creates OTEL environment variable secrets in configured namespaces (default: `ark-system`, `default`)

## Accessing Langfuse Dashboard

### Local Development Access

After installation, you have two options to access Langfuse:

**Option 1: Get credentials only**
```bash
make langfuse-credentials
# Output:
# Username: ark@ark.com
# Password: password123
# 
# To access the dashboard, run:
#   make langfuse-dashboard
```

**Option 2: Start dashboard directly (recommended)**
```bash
make langfuse-dashboard
# Output:
# Starting Langfuse dashboard...
# 
# Username: ark@ark.com
# Password: password123
# 
# Dashboard available at: http://localhost:3000
# Press Ctrl+C to stop
```

The dashboard command automatically:
- Finds an available port (starting from 3000)
- Shows you the exact URL to visit
- Starts port-forwarding to Langfuse
- Displays the login credentials

Simply visit the URL shown and login with the credentials displayed.

### Gateway API Access

Langfuse is configured with Gateway API HTTPRoute for namespace-based access:

```bash
# Access via nip.io DNS pattern
open http://langfuse.telemetry.127.0.0.1.nip.io:8080
```

## Configuration

### OTEL Environment Variables

The installation automatically configures these OpenTelemetry environment variables:

```bash
# Automatically configured by make langfuse-install
OTEL_EXPORTER_OTLP_ENDPOINT=http://langfuse-web.telemetry.svc.cluster.local:3000/api/public/otel
OTEL_EXPORTER_OTLP_HEADERS=Authorization=Basic <base64-encoded-credentials>
```

### Service Configuration

Langfuse is deployed with these default settings:

- **Namespace**: `telemetry`
- **Service Name**: `langfuse-web`
- **Port**: `3000`
- **Public Key**: `lf_pk_1234567890`
- **Secret Key**: `lf_sk_1234567890`

### Configuring Services for OTEL

The installation creates `otel-environment-variables` secrets in configured namespaces. To use in your deployments, add this to your container spec:

```yaml
containers:
- name: my-service
  envFrom:
  - secretRef:
      name: otel-environment-variables
      optional: true
```

**Note**: If deployments are already running when Langfuse is installed, restart them to pick up the OTEL configuration:

```bash
kubectl rollout restart deployment/ark-controller-devspace -n ark-system
```

To configure which namespaces receive OTEL secrets, set in `services/langfuse/chart/values.yaml`:

```yaml
otelEnvironmentVariableSecrets:
  enabled: true
  namespaces:
    - ark-system
    - default
```

## Using Langfuse Dashboard

### Dashboard Overview

Once logged in, the Langfuse dashboard provides:

**Traces View**
- Complete execution traces for ARK controller operations
- Model calls and responses
- Timing and performance metrics

**Sessions View**
- Grouped interactions and conversations
- Session-level analytics

**Models View**
- Model usage statistics
- Cost breakdown by model
- Performance comparisons

### Viewing ARK Traces

After installation, you should immediately see a 'startup' trace from the ARK controller. This confirms that telemetry is working correctly.

Traces include:
- Controller startup events
- Query execution flows
- Model interactions
- Tool executions

## Troubleshooting

### Langfuse Service Issues

```bash
# Check Langfuse pod status
kubectl get pods -l app=langfuse -n telemetry

# View Langfuse logs
kubectl logs -l app=langfuse -n telemetry

# Check service connectivity
kubectl exec -it <ark-controller-pod> -- curl http://langfuse-web.telemetry.svc.cluster.local:3000/health
```

### OTEL Configuration Issues

```bash
# Check OTEL environment variables
kubectl get secret otel-environment-variables -n ark-system -o yaml

# Check telemetry initialization logs
kubectl logs deployment/ark-controller -n ark-system | grep telemetry
```

### Dashboard Access Issues

```bash
# Check if Langfuse is ready
kubectl get deployment langfuse-web -n telemetry

# Test direct port-forward access
kubectl port-forward service/langfuse-web 5264:3000 -n telemetry

# Check Gateway API configuration
kubectl get httproute langfuse-telemetry -n telemetry -o yaml
```

## Uninstalling

To remove Langfuse and clean up OTEL configuration:

```bash
# Uninstall Langfuse and clean up OTEL secrets
make langfuse-uninstall
```

This will:
1. Remove Langfuse from the `telemetry` namespace
2. Delete OTEL environment variable secrets from `ark-system` namespace
3. Clean up installation stamps
